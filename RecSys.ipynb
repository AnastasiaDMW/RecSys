{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbdKfG5ufRphrKUctmsADm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnastasiaDMW/RecSys/blob/main/RecSys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Загрузка данных"
      ],
      "metadata": {
        "id": "FrDY3FV9zoj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import csr_matrix\n",
        "from google.colab import drive\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "movies_path = \"/content/drive/My Drive/Data/movies.csv\"\n",
        "ratings_path = \"/content/drive/My Drive/Data/ratings.csv\"\n",
        "tags_path = \"/content/drive/My Drive/Data/tags.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKdj1LMizoBh",
        "outputId": "c05e54a9-71a7-4c5d-a8e9-ac21468adb36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализация RecSys на основе подхода Content-based recommender system"
      ],
      "metadata": {
        "id": "at2sUUAjySnK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10fx4bGSzGdh",
        "outputId": "bf67ac57-68a2-42b6-bbb8-bfc2a5f7d80f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                                      title\n",
            "3608                  Stunt Man, The (1980)\n",
            "4005                       Flashback (1990)\n",
            "4681         The Great Train Robbery (1978)\n",
            "6570              Hunting Party, The (2007)\n",
            "8597  Dragonheart 2: A New Beginning (2000)\n"
          ]
        }
      ],
      "source": [
        "movies = pd.read_csv(movies_path)\n",
        "ratings = pd.read_csv(ratings_path)\n",
        "tags = pd.read_csv(tags_path)\n",
        "\n",
        "movies['genres'] = movies['genres'].str.split('|')\n",
        "genres_expanded = movies['genres'].explode()\n",
        "genres_dummies = pd.get_dummies(genres_expanded).groupby(level=0).max()\n",
        "movies_features = movies[['movieId']].join(genres_dummies)\n",
        "\n",
        "tags_grouped = tags.groupby('movieId')['tag'].apply(lambda x: ' '.join(x)).reset_index()\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "tags_tfidf = tfidf.fit_transform(tags_grouped['tag'])\n",
        "tags_tfidf_df = pd.DataFrame(tags_tfidf.toarray(), index=tags_grouped['movieId'])\n",
        "\n",
        "movies_features = movies_features.set_index('movieId').join(tags_tfidf_df, how='left').fillna(0)\n",
        "\n",
        "def recommend_movies(user_id, movies_features, ratings, top_n=10, batch_size=1000):\n",
        "    user_ratings = ratings[ratings['userId'] == user_id]\n",
        "    watched_movie_ids = user_ratings['movieId'].tolist()\n",
        "\n",
        "    if not watched_movie_ids:\n",
        "        return []\n",
        "\n",
        "    user_vector = movies_features.loc[watched_movie_ids].values\n",
        "    user_vector = np.mean(user_vector, axis=0).reshape(1, -1)\n",
        "\n",
        "    all_movie_ids = movies_features.index.tolist()\n",
        "    unseen_movie_ids = [mid for mid in all_movie_ids if mid not in watched_movie_ids]\n",
        "\n",
        "    similarities = []\n",
        "    for i in range(0, len(unseen_movie_ids), batch_size):\n",
        "        batch_ids = unseen_movie_ids[i:i+batch_size]\n",
        "        batch_vectors = movies_features.loc[batch_ids].values\n",
        "        sim = cosine_similarity(user_vector, batch_vectors)[0]\n",
        "        similarities.extend(zip(batch_ids, sim))\n",
        "\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    recommended_ids = [mid for mid, _ in similarities[:top_n]]\n",
        "\n",
        "    return recommended_ids\n",
        "\n",
        "user_id = 1\n",
        "top_recommendations = recommend_movies(user_id, movies_features, ratings, top_n=5)\n",
        "recommended_movies = movies[movies['movieId'].isin(top_recommendations)]\n",
        "print(recommended_movies[['title']])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализация RecSys на основе подхода Collaborative Recommender system - Item-Based"
      ],
      "metadata": {
        "id": "cV50viI9ykKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies = pd.read_csv(movies_path)\n",
        "ratings = pd.read_csv(ratings_path)\n",
        "tags = pd.read_csv(tags_path)\n",
        "\n",
        "user_ids = ratings['userId'].unique()\n",
        "movie_ids = ratings['movieId'].unique()\n",
        "user_id_to_index = {uid: idx for idx, uid in enumerate(user_ids)}\n",
        "movie_id_to_index = {mid: idx for idx, mid in enumerate(movie_ids)}\n",
        "index_to_movie_id = {idx: mid for mid, idx in movie_id_to_index.items()}\n",
        "\n",
        "n_users = len(user_ids)\n",
        "n_movies = len(movie_ids)\n",
        "data = ratings['rating'].values\n",
        "row = ratings['userId'].map(user_id_to_index).values\n",
        "col = ratings['movieId'].map(movie_id_to_index).values\n",
        "sparse_matrix = csr_matrix((data, (row, col)), shape=(n_users, n_movies))\n",
        "\n",
        "item_similarity = cosine_similarity(sparse_matrix.T, dense_output=False)\n",
        "\n",
        "def predict_rating(user_index, item_index, top_k=20):\n",
        "    user_ratings = sparse_matrix[user_index].toarray().flatten()\n",
        "    sim_scores = item_similarity[item_index].toarray().flatten()\n",
        "    rated_indices = user_ratings.nonzero()[0]\n",
        "    sim_scores[rated_indices] = 0\n",
        "    top_indices = np.argsort(sim_scores)[::-1][:top_k]\n",
        "    if np.sum(sim_scores[top_indices]) > 0:\n",
        "        return np.dot(sim_scores[top_indices], user_ratings[top_indices]) / np.sum(sim_scores[top_indices])\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def recommend_movies(user_id, n_recommendations=10):\n",
        "    user_index = user_id_to_index[user_id]\n",
        "    unrated_items = np.where(sparse_matrix[user_index].toarray().flatten() == 0)[0]\n",
        "    predictions = [(item, predict_rating(user_index, item)) for item in unrated_items]\n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "    top_items = predictions[:n_recommendations]\n",
        "    recommended_movie_ids = [index_to_movie_id[i] for i, _ in top_items]\n",
        "    return movies[movies['movieId'].isin(recommended_movie_ids)]\n",
        "\n",
        "print(recommend_movies(200, 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr-dU5uchGoE",
        "outputId": "c1fec5a9-bd4b-40b9-aea7-60e94896f34f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     movieId                       title                          genres\n",
            "2          3     Grumpier Old Men (1995)                  Comedy|Romance\n",
            "5          6                 Heat (1995)           Action|Crime|Thriller\n",
            "46        50  Usual Suspects, The (1995)          Crime|Mystery|Thriller\n",
            "62        70  From Dusk Till Dawn (1996)   Action|Comedy|Horror|Thriller\n",
            "89       101        Bottle Rocket (1996)  Adventure|Comedy|Crime|Romance\n",
            "124      151              Rob Roy (1995)        Action|Drama|Romance|War\n",
            "130      157       Canadian Bacon (1995)                      Comedy|War\n",
            "136      163            Desperado (1995)          Action|Romance|Western\n",
            "184      216        Billy Madison (1995)                          Comedy\n",
            "190      223               Clerks (1994)                          Comedy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Простые Реализации RecSys (С этим фильмом также смотрят, Популярное среди всех)"
      ],
      "metadata": {
        "id": "cmd0briqysJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies = pd.read_csv(movies_path)\n",
        "ratings = pd.read_csv(ratings_path)\n",
        "tags = pd.read_csv(tags_path)\n",
        "\n",
        "def also_watched(movie_id, n=5):\n",
        "    users_who_watched = ratings[ratings['movieId'] == movie_id]['userId'].unique()\n",
        "    co_movies = ratings[ratings['userId'].isin(users_who_watched)]\n",
        "    co_movies_count = co_movies.groupby('movieId').size().sort_values(ascending=False)\n",
        "    co_movies_count = co_movies_count[co_movies_count.index != movie_id]\n",
        "    top_movies = co_movies_count.head(n).index.tolist()\n",
        "    return movies[movies['movieId'].isin(top_movies)]\n",
        "\n",
        "def popular_movies(n=10):\n",
        "    movie_popularity = ratings.groupby('movieId').size().sort_values(ascending=False)\n",
        "    top_movies = movie_popularity.head(n).index.tolist()\n",
        "    return movies[movies['movieId'].isin(top_movies)]\n",
        "\n",
        "def baseline_recommendations(user_id, movie_id=None):\n",
        "    recommendations = {}\n",
        "    if movie_id is not None:\n",
        "        recommendations['also_watched'] = also_watched(movie_id, n=5)\n",
        "    recommendations['popular'] = popular_movies(n=10)\n",
        "    return recommendations\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    user_id_example = 1\n",
        "    movie_id_example = 1\n",
        "\n",
        "    recs = baseline_recommendations(user_id_example, movie_id_example)\n",
        "    for key, df in recs.items():\n",
        "        print(f\"\\n{key}\")\n",
        "        print(df[['movieId', 'title']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGV4cCGDh9ob",
        "outputId": "e6ceee03-2949-4a36-be21-61ac664ab779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "also_watched\n",
            "     movieId                                      title\n",
            "224      260  Star Wars: Episode IV - A New Hope (1977)\n",
            "257      296                        Pulp Fiction (1994)\n",
            "277      318           Shawshank Redemption, The (1994)\n",
            "314      356                        Forrest Gump (1994)\n",
            "418      480                       Jurassic Park (1993)\n",
            "\n",
            "popular\n",
            "      movieId                                      title\n",
            "97        110                          Braveheart (1995)\n",
            "224       260  Star Wars: Episode IV - A New Hope (1977)\n",
            "257       296                        Pulp Fiction (1994)\n",
            "277       318           Shawshank Redemption, The (1994)\n",
            "314       356                        Forrest Gump (1994)\n",
            "418       480                       Jurassic Park (1993)\n",
            "461       527                    Schindler's List (1993)\n",
            "507       589          Terminator 2: Judgment Day (1991)\n",
            "510       593           Silence of the Lambs, The (1991)\n",
            "1939     2571                         Matrix, The (1999)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Two-Tower"
      ],
      "metadata": {
        "id": "2RquSG8u_qgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies = pd.read_csv(movies_path)\n",
        "ratings = pd.read_csv(ratings_path)\n",
        "\n",
        "user_ids = ratings['userId'].unique()\n",
        "movie_ids = ratings['movieId'].unique()\n",
        "user2idx = {uid: idx for idx, uid in enumerate(user_ids)}\n",
        "movie2idx = {mid: idx for idx, mid in enumerate(movie_ids)}\n",
        "idx2movie = {idx: mid for mid, idx in movie2idx.items()}\n",
        "\n",
        "ratings['user_idx'] = ratings['userId'].map(user2idx)\n",
        "ratings['movie_idx'] = ratings['movieId'].map(movie2idx)\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.users = df['user_idx'].values\n",
        "        self.items = df['movie_idx'].values\n",
        "        self.ratings = df['rating'].values.astype(np.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.ratings)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
        "\n",
        "dataloader = DataLoader(MyDataset(ratings), batch_size=512, shuffle=True)\n",
        "\n",
        "class MyTwoTower(nn.Module):\n",
        "    def __init__(self, n_users, n_items, emb_dim=32):\n",
        "        super().__init__()\n",
        "        self.user_emb = nn.Embedding(n_users, emb_dim)\n",
        "        self.item_emb = nn.Embedding(n_items, emb_dim)\n",
        "    def forward(self, user_idx, item_idx):\n",
        "        u = self.user_emb(user_idx)\n",
        "        v = self.item_emb(item_idx)\n",
        "        return (u * v).sum(dim=1)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MyTwoTower(len(user_ids), len(movie_ids), emb_dim=32).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "for epoch in range(5):\n",
        "    total_loss = 0\n",
        "    for u, i, r in dataloader:\n",
        "        u, i, r = u.to(device), i.to(device), r.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(u, i)\n",
        "        loss = loss_fn(pred, r)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(r)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(ratings):.4f}\")\n",
        "\n",
        "def recommend(user_id, top_k=10):\n",
        "    user_idx = torch.tensor([user2idx[user_id]]).to(device)\n",
        "    all_items = torch.tensor(range(len(movie_ids))).to(device)\n",
        "    user_idx_expand = user_idx.repeat(len(movie_ids))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        scores = model(user_idx_expand, all_items)\n",
        "    top_indices = torch.topk(scores, top_k).indices.cpu().numpy()\n",
        "    recommended_ids = [idx2movie[i] for i in top_indices]\n",
        "    return movies[movies['movieId'].isin(recommended_ids)][['movieId','title']]\n",
        "\n",
        "print(recommend(10, top_k=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_jd-fuCwSb0",
        "outputId": "2d752aac-7b6a-4226-d59f-06568023d173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 34.3595\n",
            "Epoch 2, Loss: 17.9131\n",
            "Epoch 3, Loss: 10.7810\n",
            "Epoch 4, Loss: 5.0339\n",
            "Epoch 5, Loss: 2.4106\n",
            "      movieId                                              title\n",
            "390       449                         Fear of a Black Hat (1994)\n",
            "2251     2988                           Melvin and Howard (1980)\n",
            "2926     3925                      Stranger Than Paradise (1984)\n",
            "3240     4380  Princess and the Warrior, The (Krieger und die...\n",
            "5812    31973  Germany Year Zero (Germania anno zero) (Deutsc...\n",
            "6474    52784                                  Sharkwater (2006)\n",
            "6820    61073                                   Hell Ride (2008)\n",
            "7338    78039                              Blue Valentine (2010)\n",
            "7463    81819                                    Biutiful (2010)\n",
            "9571   174055                                     Dunkirk (2017)\n"
          ]
        }
      ]
    }
  ]
}